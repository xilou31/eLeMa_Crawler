# 饿了吗爬虫
### 关于爬虫的知识整理

这次的任务是爬取“饿了吗”上面的奶茶商家信息

大体分为五个部分：爬取、存储、、解析、代码优化、防反爬

PS:接口的获取，用chrome或者firefox都可以

首先一个大体的爬取思路是：
	1. 模拟登录
	2. 获取奶茶店铺总数
	3. 一页页去找商家
	4. 根据id去获取商家地址

1. 爬取
	1. 首先是模拟登录部分
		1. 首先先输入手机号码，然后让饿了吗发送手机验证码
		2. 这个时候有两种情况，有图片验证码（也就是让你识别字母），或者是没有图片验证码，会直接发送手机验证码
		3. 有图片验证码的情况下怎么处理呢？我们可以将验证码的图片先转为二进制，再将二进制转为png格式的图片，下载到本地。然后用电脑自带的图片播放器打开，进行人工识别并手动输入验证码。
		4. 查看手机，输入手机短信上的验证码。
		5. 模拟登录部分就是这样了。
	2. 获取奶茶店铺总数
		1. 为什么要获取奶茶店铺总数呢？
		2. 因为你第三步一页页去找商家，其实是有一个最大数量的。如果不获取奶茶店铺总数，爬虫就会去找一些没有信息的页面。
		3. 用chrome获取接口，post即可
	3. 一页页去找商家
		1. 观察饿了吗的页面，可以看到饿了吗每个页面会显示8个商家
		2. 所以我们设置每次获取8个商家，直到超过奶茶店铺总数
	4. 获取商家地址
		1. 商家的地址有点特别，是要点开具体的商家，才能看到地址
		2. 而饿了吗后台给每个商家分配了一个单独的商家id
		3. 这个id去哪里获取呢？仔细分析后，可以看到我们在一页页找商家的时候，获取商家经纬度的时候，同时也可以获取到商家的id
		4. 所以我们前面存储商家的id，用来获取商家地址
		5. 最后把商家id删除即可
2. 解析
	解析部分没什么好讲的，主要就是将页面信息或者将服务器返回的数据，提取出自己想要的。
	一般来说，静态页面用BeautifulSoup这个库来解析。动态页面，用json这个库，将数据转化为json格式。
	另外，还有正则化，css解析器等等。
3. 存储
	存储过程中有一个很大的问题，就是两个很近的地方，可能获取的商家信息基本都是重复的。所以去重是一个问题。另外就是，数据其实是存储在内存里面的，万一爬取的数据太多，内存不够放怎么办？
	
	1. 去重
		去重的话，我们可以将数据先转为pandas的DataFrame，然后DataFrame有一个内置函数可以去重。
	2. 数据库
		内存的大小是有限的。我们可以这样处理，在本地安装mysql，然后每次爬取一个地址，就将那里的数据存储在mysql数据库里面，然后再将内存里面的数据释放掉。 因为有内存回收机制，这样内存绝对够用。
		当然我这里没有用过数据库。
4. 代码优化
	我在爬取过程中发现，爬取速度异常的慢QAQ
	提供几种加速的思路。

	1. 多线程
		线程是操作系统能够进行运算调度的最小单位。多线程相当于有多个爬虫同时爬取。但是一定要注意，一定要防止堵塞，也就是要异步执行，下面几种相同。
	2. 多进程
		进程在线程之上。我在代码中就是使用了多进程。还挺方便的，毕竟python有多进程和多线程的库，可以查一下官方文档即可使用。
	3. 分布式
		分布式我没接触过，但是分布式可以更加快的加速爬取的速度。分布式通俗的讲，就是多台电脑一起爬取。可以将一个爬取任务，细分为多个子任务。每个电脑完成自己的任务后，再将自己的那部分数据上传，最终整合起来。
	线程<进程<电脑，所以速度上多线程<多进程<分布式。
5. 防反爬
	我在爬取的时候，深受反爬制度的打击。
	好一点的，封ip。差一点的，直接把账号给封了。最严重的是，有一天刚好不是很幸运，加密手段换了。当然不是因为我才换得，是刚好他们公司打算换，所以就只能换一种方式来爬取了。

	解决方式：
	1. 封ip的话，可以使用代理池。见过身边有同学做过代理池，也用过，不过原理不是很清楚。
	2. 获取cookie。一般浏览器是怎么样知道你是登录的呢，是通过cookie或者token。一般是，当你登录的时候，登录服务器会将一段口令，当然生成口令的算法只有别人才知道。它会将口令存储在登陆服务器上，同时也会发到你的电脑或者手机上。当你尝试获取信息时，服务器就会找他自己服务器里面有没有这个口令，如果有代表已经登录。
	3. 模拟浏览器行为。怎么说呢？有一个库叫做selenium，它可以控制浏览器行为，比如你在电脑上输入代码，让浏览器打开某个网址。那么浏览器真的可以打开那个网址。也可以模拟上划滚动等等行为。所以这种方法也是没那么容易被封的，因为他跟用户的行为是相同的，就是爬取速度比较慢就是了，但是是自动化的。

